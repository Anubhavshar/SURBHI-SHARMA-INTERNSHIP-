{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5556d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1185b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.1 scrape details of most viewed videows on youtube from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23298bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce406a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd1ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Gangnam Style\"‚ÅÇ[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Baby\"*[66]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bad Romance\"[70]</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Charlie Bit My Finger\"‚Ä°[74]</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Evolution of Dance\"[77]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Girlfriend\"‚Ä°[79][80]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Evolution of Dance\"[77]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‚Ä°[84]</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Evolution of Dance\"*[77]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Pok√©mon Theme Music Video\"‚Ä°[90]</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Myspace ‚Äì The Movie\"‚Ä°[95][96]</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Phony Photo Booth\"‚Ä°[99]</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‚Ä°[101]</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Cross Bar\"‚Ä°[103]</td>\n",
       "      <td>joeB</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>December 10, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‚Ä°*[105]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"I/O Brush\"‚Ä°*[108]</td>\n",
       "      <td>larfus</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Me at the zoo\"[111]</td>\n",
       "      <td>jawed</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>April 23, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rank  \\\n",
       "0                \"Baby Shark Dance\"[6]   \n",
       "1                       \"Despacito\"[9]   \n",
       "2                  \"See You Again\"[21]   \n",
       "3                 \"Gangnam Style\"‚ÅÇ[30]   \n",
       "4                          \"Baby\"*[66]   \n",
       "5                    \"Bad Romance\"[70]   \n",
       "6         \"Charlie Bit My Finger\"‚Ä°[74]   \n",
       "7             \"Evolution of Dance\"[77]   \n",
       "8                \"Girlfriend\"‚Ä°[79][80]   \n",
       "9             \"Evolution of Dance\"[77]   \n",
       "10      \"Music Is My Hot Hot Sex\"‚Ä°[84]   \n",
       "11           \"Evolution of Dance\"*[77]   \n",
       "12    \"Pok√©mon Theme Music Video\"‚Ä°[90]   \n",
       "13      \"Myspace ‚Äì The Movie\"‚Ä°[95][96]   \n",
       "14            \"Phony Photo Booth\"‚Ä°[99]   \n",
       "15   \"The Chronic of Narnia Rap\"‚Ä°[101]   \n",
       "16                   \"Cross Bar\"‚Ä°[103]   \n",
       "17  \"Ronaldinho: Touch of Gold\"‚Ä°*[105]   \n",
       "18                  \"I/O Brush\"‚Ä°*[108]   \n",
       "19                \"Me at the zoo\"[111]   \n",
       "\n",
       "                                     Video_Name        Upload_Date  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                    Luis Fonsi   January 12, 2017   \n",
       "2                                   Wiz Khalifa      April 6, 2015   \n",
       "3                                           Psy      July 15, 2012   \n",
       "4                                 Justin Bieber  February 19, 2010   \n",
       "5                                     Lady Gaga  November 24, 2009   \n",
       "6                                         HDCYT       May 22, 2007   \n",
       "7                                Judson Laipply      April 6, 2006   \n",
       "8                                   RCA Records  February 27, 2007   \n",
       "9                                Judson Laipply      April 6, 2006   \n",
       "10                               CLARUSBARTEL72      April 9, 2007   \n",
       "11                               Judson Laipply      April 6, 2006   \n",
       "12                                        Smosh  November 28, 2005   \n",
       "13                                       eggtea   January 31, 2006   \n",
       "14                                    mugenized   December 1, 2005   \n",
       "15                                  youtubedude  December 18, 2005   \n",
       "16                                         joeB   October 21, 2005   \n",
       "17                                   Nikesoccer   October 21, 2005   \n",
       "18                                       larfus    October 5, 2005   \n",
       "19                                        jawed     April 23, 2005   \n",
       "\n",
       "                Views  \n",
       "0    November 2, 2020  \n",
       "1      August 4, 2017  \n",
       "2       July 10, 2017  \n",
       "3   November 24, 2012  \n",
       "4       July 16, 2010  \n",
       "5      April 14, 2010  \n",
       "6    October 25, 2009  \n",
       "7         May 2, 2009  \n",
       "8       July 17, 2008  \n",
       "9      March 15, 2008  \n",
       "10      March 1, 2008  \n",
       "11       May 19, 2006  \n",
       "12     March 12, 2006  \n",
       "13  February 18, 2006  \n",
       "14   January 21, 2006  \n",
       "15    January 9, 2006  \n",
       "16  December 10, 2005  \n",
       "17   October 31, 2005  \n",
       "18   October 29, 2005  \n",
       "19     April 23, 2005  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank=[]\n",
    "Video_Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]\n",
    "\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[1]\")\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except:\n",
    "    Rank.append('-')\n",
    "    \n",
    "try:\n",
    "    vn=driver.find_elements(By.XPATH,\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[2]\")\n",
    "    for i in vn:\n",
    "        Video_Name.append(i.text)\n",
    "except:\n",
    "    Video_Name.append('-')\n",
    "    \n",
    "\n",
    "    \n",
    "try:\n",
    "    ud=driver.find_elements(By.XPATH,\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[4]\")\n",
    "    for i in ud:\n",
    "        Upload_Date.append(i.text)\n",
    "except:\n",
    "    Upload_Date.append('-')\n",
    "    \n",
    "try:\n",
    "    vw=driver.find_elements(By.XPATH,\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[5]\")\n",
    "    for i in vw:\n",
    "        Views.append(i.text)\n",
    "except:\n",
    "    Views.append('-')\n",
    "    \n",
    "print(len(Rank))\n",
    "print(len(Video_Name))\n",
    "\n",
    "print(len(Upload_Date))\n",
    "print(len(Views))\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Rank': Rank,\n",
    "                'Video_Name':Video_Name,\n",
    "                 \n",
    "                 'Upload_Date': Upload_Date,\n",
    "                 'Views': Views,\n",
    "                })\n",
    "#printing dataframe\n",
    "df        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.4 Scrape the details of trending repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1464301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6df02eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "btn_clk = driver.find_element(By.XPATH,\"//ul[@class='d-lg-flex list-style-none']//li[3]//button\")\n",
    "btn_clk.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "trending_option = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "trending_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dba3d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChaoningZhang /</td>\n",
       "      <td>This is the offiicial code for Faster Segment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramonvc /</td>\n",
       "      <td>GPT 3.5/4 with a Chat Web UI. No API key requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THUDM /</td>\n",
       "      <td>ChatGLM2-6B: An Open Bilingual Chat LLM | ÂºÄÊ∫êÂèåËØ≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PowerShell /</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XingangPan /</td>\n",
       "      <td>Official Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hiyouga /</td>\n",
       "      <td>Fine-tuning ChatGLM-6B with PEFT | Âü∫‰∫é PEFT ÁöÑÈ´òÊïà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>facebook /</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THUDM /</td>\n",
       "      <td>ChatGLM-6B: An Open Bilingual Dialogue Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>practical-tutorials /</td>\n",
       "      <td>Curated list of project-based tutorials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sohamkamani /</td>\n",
       "      <td>An ultra-simplified explanation of design patt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>papers-we-love /</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cvg /</td>\n",
       "      <td>LightGlue: Local Feature Matching at Light Speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>turboderp /</td>\n",
       "      <td>A more memory-efficient rewrite of the HF tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fuqiuluo /</td>\n",
       "      <td>Ëé∑ÂèñQQSignÈÄöËøáUnidbg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jasontaylordev /</td>\n",
       "      <td>Clean Architecture Solution Template for ASP.N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>toeverything /</td>\n",
       "      <td>There can be more than Notion and Miro. AFFiNE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ripienaar /</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EbookFoundation /</td>\n",
       "      <td>üìö Freely available programming books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chat2db /</td>\n",
       "      <td>üî• üî• üî• An intelligent and versatile general-pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PlexPt /</td>\n",
       "      <td>ChatGPT ‰∏≠ÊñáË∞ÉÊïôÊåáÂçó„ÄÇÂêÑÁßçÂú∫ÊôØ‰ΩøÁî®ÊåáÂçó„ÄÇÂ≠¶‰π†ÊÄé‰πàËÆ©ÂÆÉÂê¨‰Ω†ÁöÑËØù„ÄÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>labmlai /</td>\n",
       "      <td>üßë‚Äçüè´ 59 Implementations/tutorials of deep learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>microsoft /</td>\n",
       "      <td>24 Lessons, 12 Weeks, Get Started as a Web Dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dragonflydb /</td>\n",
       "      <td>A modern replacement for Redis and Memcached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wgwang /</td>\n",
       "      <td>‰∏≠ÂõΩÂ§ßÊ®°Âûã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>StanGirard /</td>\n",
       "      <td>üß† Dump all your files into your private Genera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Repository_title                             Repository_description\n",
       "0         ChaoningZhang /  This is the offiicial code for Faster Segment ...\n",
       "1               ramonvc /  GPT 3.5/4 with a Chat Web UI. No API key requi...\n",
       "2                 THUDM /  ChatGLM2-6B: An Open Bilingual Chat LLM | ÂºÄÊ∫êÂèåËØ≠...\n",
       "3            PowerShell /                       PowerShell for every system!\n",
       "4            XingangPan /          Official Code for DragGAN (SIGGRAPH 2023)\n",
       "5               hiyouga /  Fine-tuning ChatGLM-6B with PEFT | Âü∫‰∫é PEFT ÁöÑÈ´òÊïà...\n",
       "6              facebook /  An open-source C++ library developed and used ...\n",
       "7                 THUDM /  ChatGLM-6B: An Open Bilingual Dialogue Languag...\n",
       "8   practical-tutorials /            Curated list of project-based tutorials\n",
       "9           sohamkamani /  An ultra-simplified explanation of design patt...\n",
       "10       papers-we-love /  Papers from the computer science community to ...\n",
       "11                  cvg /   LightGlue: Local Feature Matching at Light Speed\n",
       "12            turboderp /  A more memory-efficient rewrite of the HF tran...\n",
       "13             fuqiuluo /                                   Ëé∑ÂèñQQSignÈÄöËøáUnidbg\n",
       "14       jasontaylordev /  Clean Architecture Solution Template for ASP.N...\n",
       "15         toeverything /  There can be more than Notion and Miro. AFFiNE...\n",
       "16            ripienaar /  A list of SaaS, PaaS and IaaS offerings that h...\n",
       "17      EbookFoundation /               üìö Freely available programming books\n",
       "18              chat2db /  üî• üî• üî• An intelligent and versatile general-pur...\n",
       "19               PlexPt /                ChatGPT ‰∏≠ÊñáË∞ÉÊïôÊåáÂçó„ÄÇÂêÑÁßçÂú∫ÊôØ‰ΩøÁî®ÊåáÂçó„ÄÇÂ≠¶‰π†ÊÄé‰πàËÆ©ÂÆÉÂê¨‰Ω†ÁöÑËØù„ÄÇ\n",
       "20              labmlai /  üßë‚Äçüè´ 59 Implementations/tutorials of deep learn...\n",
       "21            microsoft /  24 Lessons, 12 Weeks, Get Started as a Web Dev...\n",
       "22          dragonflydb /       A modern replacement for Redis and Memcached\n",
       "23               wgwang /                                              ‰∏≠ÂõΩÂ§ßÊ®°Âûã\n",
       "24           StanGirard /  üß† Dump all your files into your private Genera..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_title = []\n",
    "Repository_description =[]\n",
    "Contributors_counts =[]\n",
    "Language_used = []\n",
    "\n",
    "try:\n",
    "    title=driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "    for i in title:\n",
    "        Repository_title.append(i.text)\n",
    "except:\n",
    "    Repository_title.append('-')\n",
    "    \n",
    "try:\n",
    "    desc=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for i in desc:\n",
    "        Repository_description.append(i.text)\n",
    "        \n",
    "except:\n",
    "    Repository_description.append('-')\n",
    "    \n",
    "\n",
    "\n",
    "print(len(Repository_title))\n",
    "print(len(Repository_description))\n",
    "\n",
    "df=pd.DataFrame({'Repository_title':Repository_title,\n",
    "                 'Repository_description':Repository_description\n",
    "                \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fa1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.8 Details of dataset from UCI machine learning repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2bde01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16511e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/'  \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb31070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_view=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "button_view.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeeac175",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "expand_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cdec4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_url=[]\n",
    "url=driver.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]')\n",
    "for i in url:\n",
    "    product_url.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be97793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>17 Attributes</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Attributes</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Attributes</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Attributes</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Attributes</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset_name     Data_type            Task  \\\n",
       "0                                  Iris  Multivariate  Classification   \n",
       "1                         Heart Disease  Multivariate  Classification   \n",
       "2                                 Adult  Multivariate  Classification   \n",
       "3                      Dry Bean Dataset  Multivariate  Classification   \n",
       "4                              Diabetes                                 \n",
       "5            Rice (Cammeo and Osmancik)  Multivariate  Classification   \n",
       "6                                  Wine  Multivariate  Classification   \n",
       "7                        Car Evaluation  Multivariate  Classification   \n",
       "8  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "9                              Mushroom  Multivariate  Classification   \n",
       "\n",
       "               Attribute_type   No_of_instances No_of_attribute       Year  \n",
       "0                        Real     150 Instances    4 Attributes   7/1/1988  \n",
       "1  Categorical, Integer, Real     303 Instances   13 Attributes   7/1/1988  \n",
       "2        Categorical, Integer  48.84K Instances   14 Attributes   5/1/1996  \n",
       "3               Integer, Real  13.61K Instances   17 Attributes  9/14/2020  \n",
       "4        Categorical, Integer                     20 Attributes        N/A  \n",
       "5                        Real   3.81K Instances    8 Attributes  10/6/2019  \n",
       "6               Integer, Real     178 Instances   13 Attributes   7/1/1991  \n",
       "7                 Categorical   1.73K Instances    6 Attributes   6/1/1997  \n",
       "8                        Real     569 Instances   30 Attributes  11/1/1995  \n",
       "9                 Categorical   8.12K Instances   22 Attributes  4/27/1987  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "\n",
    "#for url in product_url:\n",
    " #   driver.get(url)\n",
    "    \n",
    "    \n",
    "    \n",
    "try:   # Extracting Dataset_name from the xpath\n",
    "    name=driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]')\n",
    "    for i in name:\n",
    "        Dataset_name.append(i.text)\n",
    "except:\n",
    "    Dataset_name.append('-')\n",
    "try:   # Extracting Data_type from the xpath\n",
    "    type=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "    for i in type:\n",
    "         Data_type.append(i.text)\n",
    "except:\n",
    "    Data_type.append('-')\n",
    "    \n",
    "\n",
    "try:   # Extracting task from the xpath\n",
    "    task=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "    for i in task:\n",
    "        Task.append(i.text)\n",
    "except:\n",
    "    Task.append('-')\n",
    "    \n",
    "try:   # Extracting Attribute_type from the xpath\n",
    "    attribute=driver.find_elements(By.XPATH,'//*[@class=\"border\"]/tr/td[2]')\n",
    "    for i in attribute:\n",
    "        Attribute_type.append(i.text)\n",
    "except:\n",
    "    Attribute_type.append('-')\n",
    "    \n",
    "try:   # Extracting No_of_instances from the xpath\n",
    "    instances=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "    for i in instances:\n",
    "        No_of_instances.append(i.text)\n",
    "except:\n",
    "    No_of_instances.append('-')\n",
    "try:   # Extracting No_of_attribute from the xpath\n",
    "    attribute1=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "    for i in attribute1:\n",
    "        No_of_attribute.append(i.text)\n",
    "except:\n",
    "    No_of_attribute.append('-')\n",
    "    \n",
    "    \n",
    "try:   # Extracting Year from the xpath\n",
    "    year=driver.find_elements(By.XPATH,'//*[@class=\"border\"]/tr/td[3]')\n",
    "    for i in year:\n",
    "        Year.append(i.text)\n",
    "except:\n",
    "    Year.append('-')\n",
    "\n",
    "#time.sleep(4)#delay for 4 seconds\n",
    "\n",
    "#creating a dataframe\n",
    "print(len(Dataset_name))\n",
    "print(len(Data_type))\n",
    "print(len(Task))\n",
    "print(len(Attribute_type))\n",
    "print(len(No_of_instances))\n",
    "print(len(No_of_attribute))\n",
    "print(len(Year))\n",
    "df=pd.DataFrame({'Dataset_name':Dataset_name,\n",
    "                'Data_type':Data_type,\n",
    "                'Task':Task,\n",
    "                'Attribute_type': Attribute_type,\n",
    "                'No_of_instances': No_of_instances,\n",
    "                 'No_of_attribute': No_of_attribute,\n",
    "                 'Year': Year,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547dcace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.3 scrape the details of statewiese GDP of INDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "040c426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cda2478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://statisticstimes.com/'  #Opening the statistics.com website\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "385be22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_eco = driver.find_element(By.XPATH,\"//button[@class='dropbtn']//..//..//div[2]//button\")\n",
    "clk_eco.click()#clicking Economy button\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "717c61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_india = driver.find_element(By.XPATH,\"//div[@class='dropdown-content']//..//..//div[2]//div//a[3]\") \n",
    "clk_india.click()#clicking India button\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71fb6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_stateGDP = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "clk_stateGDP.click()#clicking StateGDP button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14e74cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP19-20</th>\n",
       "      <th>GSDP18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State  GSDP19-20  GSDP18-19   Share      GDP\n",
       "0     1                Maharashtra          -  2,632,792  13.94%  399.921\n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%  247.629\n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%  240.726\n",
       "3     4                    Gujarat          -  1,502,899   7.96%  228.290\n",
       "4     5                  Karnataka  1,631,977  1,493,127   7.91%  226.806\n",
       "5     6                West Bengal  1,253,832  1,089,898   5.77%  165.556\n",
       "6     7                  Rajasthan  1,020,989    942,586   4.99%  143.179\n",
       "7     8             Andhra Pradesh    972,782    862,957   4.57%  131.083\n",
       "8     9                  Telangana    969,604    861,031   4.56%  130.791\n",
       "9    10             Madhya Pradesh    906,672    809,592   4.29%  122.977\n",
       "10   11                     Kerala          -    781,653   4.14%  118.733\n",
       "11   12                      Delhi    856,112    774,870   4.10%  117.703\n",
       "12   13                    Haryana    831,610    734,163   3.89%  111.519\n",
       "13   14                      Bihar    611,804    530,363   2.81%   80.562\n",
       "14   15                     Punjab    574,760    526,376   2.79%   79.957\n",
       "15   16                     Odisha    521,275    487,805   2.58%   74.098\n",
       "16   17                      Assam          -    315,881   1.67%   47.982\n",
       "17   18               Chhattisgarh    329,180    304,063   1.61%   46.187\n",
       "18   19                  Jharkhand    328,598    297,204   1.57%   45.145\n",
       "19   20                Uttarakhand          -    245,895   1.30%   37.351\n",
       "20   21            Jammu & Kashmir          -    155,956   0.83%   23.690\n",
       "21   22           Himachal Pradesh    165,472    153,845   0.81%   23.369\n",
       "22   23                        Goa     80,449     73,170   0.39%   11.115\n",
       "23   24                    Tripura     55,984     49,845   0.26%    7.571\n",
       "24   25                 Chandigarh          -     42,114   0.22%    6.397\n",
       "25   26                 Puducherry     38,253     34,433   0.18%    5.230\n",
       "26   27                  Meghalaya     36,572     33,481   0.18%    5.086\n",
       "27   28                     Sikkim     32,496     28,723   0.15%    4.363\n",
       "28   29                    Manipur     31,790     27,870   0.15%    4.233\n",
       "29   30                   Nagaland          -     27,283   0.14%    4.144\n",
       "30   31          Arunachal Pradesh          -     24,603   0.13%    3.737\n",
       "31   32                    Mizoram     26,503     22,287   0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -       -        -"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "GSDP1=[]\n",
    "GSDP2=[]\n",
    "share=[]\n",
    "GDP=[]\n",
    "urls=[]\n",
    "\n",
    "try:   # Extracting rank from the xpath\n",
    "    ranks=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]//tbody//tr//td[1]')\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except:\n",
    "    rank.append('-')\n",
    "\n",
    "\n",
    "try:  # Extracting state from the xpath\n",
    "    states=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]//tbody//tr//td[2]')\n",
    "    for i in states:\n",
    "        state.append(i.text)\n",
    "except:\n",
    "    state.append('-')\n",
    "\n",
    "\n",
    "try:   # Extracting gsdp1 from the xpath\n",
    "    gsdp1=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]//tbody//tr//td[3]')\n",
    "    for i in gsdp1:\n",
    "        GSDP1.append(i.text)\n",
    "except:\n",
    "    GSDP1.append('-')\n",
    "\n",
    "try:   # Extracting gsdp2 from the xpath\n",
    "    gsdp2=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]//tbody//tr//td[4]')\n",
    "    for i in gsdp2:\n",
    "        GSDP2.append(i.text)\n",
    "except:\n",
    "    GSDP2.append('-')\n",
    "\n",
    "try:   # Extracting share from the xpath\n",
    "    shares=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]//tbody//tr//td[5]')\n",
    "    for i in shares:\n",
    "        share.append(i.text)\n",
    "except:\n",
    "    share.append('-')\n",
    "\n",
    "\n",
    "try:    # Extracting GDP from the xpath\n",
    "    gdp=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]//tbody//tr//td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except:\n",
    "    GDP.append('-')\n",
    "\n",
    "\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Rank':rank,\n",
    "                'State':state,\n",
    "                'GSDP19-20':GSDP1,\n",
    "                'GSDP18-19': GSDP2,\n",
    "                'Share': share,\n",
    "                'GDP':GDP})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd54f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.4 scrape details of trending reppositories on Github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17d350f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/' #Opening the Github.com\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b0a6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_explore = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button\")\n",
    "clk_explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d688dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_open=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "clk_open.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d76a2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_trending=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]\")\n",
    "clk_trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.7 Scrape the details of most watched TVseries of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d4570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a973e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.imdb.com/list/ls095964455')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f021634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>2,173,715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>1,251,542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>1,032,493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>303,560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>262,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>51,957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>63,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>208,546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>43,402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>260,203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016‚Äì2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013‚Äì2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005‚Äì )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time      Votes  \n",
       "0    57 min  2,173,715  \n",
       "1    51 min  1,251,542  \n",
       "2    44 min  1,032,493  \n",
       "3    60 min    303,560  \n",
       "4    43 min    262,731  \n",
       "..      ...        ...  \n",
       "95   42 min     51,957  \n",
       "96   50 min     63,993  \n",
       "97   42 min    208,546  \n",
       "98   45 min     43,402  \n",
       "99  572 min    260,203  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Empty List\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "try:   # Extracting name from the xpath\n",
    "    name=driver.find_elements(By.XPATH,\"//*[@class='lister-item-header']//a\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except:\n",
    "    Name.append('-')\n",
    "    \n",
    "try:   # Extracting year span from the xpath\n",
    "    year=driver.find_elements(By.XPATH,\"//*[@class='lister-item-header']//span[2]\")\n",
    "    for i in year:\n",
    "        Year_span.append(i.text)\n",
    "except:\n",
    "    Year_span.append('-')\n",
    "    \n",
    "try:  # Extracting genre from the xpath\n",
    "    genre=driver.find_elements(By.XPATH,\"//*[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except:\n",
    "    Genre.append('-')\n",
    "    \n",
    "try:   # Extracting run time from the xpath\n",
    "    run_time=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in run_time:\n",
    "        Run_time.append(i.text)\n",
    "except:\n",
    "    Run_time.append('-')\n",
    "    \n",
    "try:   # Extracting ratings from the xpath\n",
    "    ratings=driver.find_elements(By.XPATH,\"/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/div[1]/div[1]/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except:\n",
    "    Ratings.append('-')\n",
    "    \n",
    "try:   # Extracting votes from the xpath\n",
    "    votes=driver.find_elements(By.XPATH,\"//*[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except:\n",
    "    Votes.append('-')\n",
    "    \n",
    "    \n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Name':Name,\n",
    "                'Year_span':Year_span,\n",
    "                'Genre':Genre,\n",
    "                'Run_time': Run_time,\n",
    "                'Votes': Votes,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.6Scrape details of highest selling novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39cac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762c0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'  #Open the website by using driver.get\n",
    "driver.get(url) #opening the guardian.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbd55d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name       Author_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "try:   #Extracting week on book name from the xpath\n",
    "    book_name=driver.find_elements(By.XPATH,\"//*[@class='in-article sortable']//tbody//tr//td[2]\")\n",
    "    for i in book_name:\n",
    "        Book_name.append(i.text)\n",
    "except:\n",
    "    Book_name.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "        \n",
    "try:   # Extracting week on author name from the xpath\n",
    "    author_name=driver.find_elements(By.XPATH,\"//*[@class='in-article sortable']//tbody//tr//td[3]\")\n",
    "    for i in author_name:\n",
    "        Author_name.append(i.text)\n",
    "except:\n",
    "    Author_name.append('-') \n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   # Extracting volumes sold from the xpath\n",
    "    vol_sold=driver.find_elements(By.XPATH,\"//*[@class='in-article sortable']//tbody//tr//td[4]\")\n",
    "    for i in vol_sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except:\n",
    "    Volumes_sold.append('-') \n",
    "    \n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   # Extracting publisher from the xpath\n",
    "    publisher=driver.find_elements(By.XPATH,\"//*[@class='in-article sortable']//tbody//tr//td[5]\")\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except:\n",
    "    Publisher.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   # Extracting genre from the xpath\n",
    "    genre=driver.find_elements(By.XPATH,\"//*[@class='in-article sortable']//tbody//tr//td[6]\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except:\n",
    "    Genre.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Book_Name':Book_name,\n",
    "                'Author_Name':Author_name,\n",
    "                'Volumes_Sold':Volumes_sold,\n",
    "                'Publisher': Publisher,\n",
    "                'Genre': Genre,\n",
    "                })\n",
    "#printing dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.5 Scrape the details of top 100 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b911bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e96d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.billboard.com/'  #Opening the billboards\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf3fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk = driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "clk.click() #clicking the button\n",
    "\n",
    "time.sleep(3) #delay for 3 seconds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c72bd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_chart = driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a\") \n",
    "clk_chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0d8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_100hot = driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a\") \n",
    " \n",
    "clk_100hot.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3106ade4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_Week_Ranks</th>\n",
       "      <th>Peak_Ranks</th>\n",
       "      <th>Week_On_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Angel, Pt. 1</td>\n",
       "      <td>Kodak Black, NLE Choppa, Jimin, JVKE &amp; Muni Long</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>Parmalee</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Moonlight</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Classy 101</td>\n",
       "      <td>Feid x Young Miko</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bluffin</td>\n",
       "      <td>Gucci Mane &amp; Lil Baby</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song_Name                                       Artist_Name  \\\n",
       "0     Last Night                                     Morgan Wallen   \n",
       "1       Fast Car                                        Luke Combs   \n",
       "2      Calm Down                               Rema & Selena Gomez   \n",
       "3        Flowers                                       Miley Cyrus   \n",
       "4    All My Life                        Lil Durk Featuring J. Cole   \n",
       "..           ...                                               ...   \n",
       "95  Angel, Pt. 1  Kodak Black, NLE Choppa, Jimin, JVKE & Muni Long   \n",
       "96  Girl In Mine                                          Parmalee   \n",
       "97     Moonlight                                        Kali Uchis   \n",
       "98    Classy 101                                 Feid x Young Miko   \n",
       "99       Bluffin                             Gucci Mane & Lil Baby   \n",
       "\n",
       "   Last_Week_Ranks Peak_Ranks Week_On_Board  \n",
       "0                1          1            21  \n",
       "1                3          2            13  \n",
       "2                4          3            42  \n",
       "3                2          1            23  \n",
       "4                5          2             6  \n",
       "..             ...        ...           ...  \n",
       "95               -         65             2  \n",
       "96               -         97             1  \n",
       "97              90         80            11  \n",
       "98               -         99             1  \n",
       "99               -        100             1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Week_on_board=[]\n",
    "\n",
    "try:   # Extracting song name from the xpath\n",
    "    song_name=driver.find_elements(By.XPATH,\"//*[@class='lrv-u-width-100p']//ul//li//h3\")\n",
    "    for i in song_name:\n",
    "        Song_name.append(i.text)\n",
    "except:\n",
    "    Song_name.append('-')\n",
    "    \n",
    "try:   # Extracting artist name from the xpath\n",
    "    artist_name=driver.find_elements(By.XPATH,\"//*[@class='lrv-u-width-100p']//ul//li[1]//span\")\n",
    "    for i in artist_name:\n",
    "        Artist_name.append(i.text)\n",
    "except:\n",
    "    Artist_name.append('-')\n",
    "\n",
    "try:   # Extracting last week rank from the xpath\n",
    "    Last_week_ranks=driver.find_elements(By.XPATH,\"//*[@class='lrv-u-width-100p']//ul//li[4]//span\")\n",
    "    for i in Last_week_ranks:\n",
    "        Last_week_rank.append(i.text)\n",
    "except:\n",
    "    Last_week_rank.append('-')\n",
    "    \n",
    "lst=[]#rejection list\n",
    "last_week_ranks=[]#final list\n",
    "for i in range(0, len(Last_week_rank)): #extracting even and odd index details separately.\n",
    "    if i % 2:\n",
    "        lst.append(Last_week_rank[i])#rejecting odd index details\n",
    "    else :\n",
    "        last_week_ranks.append(Last_week_rank[i])#extracting even index details\n",
    "\n",
    "try:   # Extracting peak ranks from the xpath\n",
    "    peak_ranks=driver.find_elements(By.XPATH,\"//*[@class='lrv-u-width-100p']//ul//li[5]//span\")\n",
    "    for i in peak_ranks:\n",
    "        Peak_rank.append(i.text)\n",
    "except:\n",
    "    Peak_rank.append('-')\n",
    "\n",
    "peak=[]#rejection list\n",
    "Peak_ranks=[]#final list\n",
    "\n",
    "for i in range(0, len(Peak_rank)):#extracting even and odd index details separately.\n",
    "    if i % 2:\n",
    "        peak.append(Peak_rank[i])#rejecting odd index details\n",
    "    else :\n",
    "        Peak_ranks.append(Peak_rank[i])#extracting even index details\n",
    "        \n",
    "try:   # Extracting week on boards from the xpath\n",
    "    Week_on_boards1=driver.find_elements(By.XPATH,\"//*[@class='lrv-u-width-100p']//ul//li[6]//span\")\n",
    "    for i in Week_on_boards1:\n",
    "        Week_on_board.append(i.text)\n",
    "except:\n",
    "    Week_on_board.append('-')\n",
    "\n",
    "week=[]#rejection list\n",
    "Weeks_on_boards=[]#final list\n",
    "\n",
    "for i in range(0, len(Week_on_board)):#extracting even and odd index details separately.\n",
    "    if i % 2:\n",
    "        week.append(Week_on_board[i])#rejecting odd index details\n",
    "    else :\n",
    "        Weeks_on_boards.append(Week_on_board[i])#extracting even index details\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Song_Name':Song_name,\n",
    "                'Artist_Name':Artist_name,\n",
    "                'Last_Week_Ranks':last_week_ranks,\n",
    "                'Peak_Ranks': Peak_ranks,\n",
    "                'Week_On_Board': Week_on_board,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcb611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2 Scrape details of team india's international fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6544e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"c:\\User\\Admin\\Desktop\\selenium_driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33f7b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv/'  #Opening the bcci.tv\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cafaeb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk_international = driver.find_element(By.XPATH,\"/html/body/nav/div/div[2]/ul[1]/li[2]/a\")\n",
    "clk_international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07b891d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>9 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>11 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Dominica</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>13 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>16 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>19 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Trinidad</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>22 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                               Series     Place         Date  \\\n",
       "0   1st T20I   INDIA WOMEN TOUR OF BANGLADESH 2023     Dhaka   9 JUL 2023   \n",
       "1   2nd T20I   INDIA WOMEN TOUR OF BANGLADESH 2023     Dhaka  11 JUL 2023   \n",
       "2   1st Test        INDIA TOUR OF WEST INDIES 2023  Dominica  12 JUL 2023   \n",
       "3   3rd T20I   INDIA WOMEN TOUR OF BANGLADESH 2023     Dhaka  13 JUL 2023   \n",
       "4    1st ODI   INDIA WOMEN TOUR OF BANGLADESH 2023     Dhaka  16 JUL 2023   \n",
       "5    2nd ODI   INDIA WOMEN TOUR OF BANGLADESH 2023     Dhaka  19 JUL 2023   \n",
       "6   2nd Test        INDIA TOUR OF WEST INDIES 2023  Trinidad  20 JUL 2023   \n",
       "7    3rd ODI   INDIA WOMEN TOUR OF BANGLADESH 2023     Dhaka  22 JUL 2023   \n",
       "\n",
       "          Time  \n",
       "0  1:30 PM IST  \n",
       "1  1:30 PM IST  \n",
       "2  7:30 PM IST  \n",
       "3  1:30 PM IST  \n",
       "4  9:00 AM IST  \n",
       "5  9:00 AM IST  \n",
       "6  7:30 PM IST  \n",
       "7  9:00 AM IST  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "#Extracting Match title by using xpath\n",
    "title=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title:\n",
    "    match_title.append(i.text.split('-').pop(0))\n",
    "#Extracting series by using xpath \n",
    "series=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "#Extracting place by using xpath\n",
    "place=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in place:\n",
    "    Place.append(i.text)\n",
    "#Extracting Date by using xpath   \n",
    "date=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date:\n",
    "    Date.append(i.text)\n",
    "#Extracting Time by using xpath   \n",
    "time=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Match_Title':match_title,\n",
    "                'Series':Series,\n",
    "                'Place':Place,\n",
    "                'Date': Date,\n",
    "                'Time': Time,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6403507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
